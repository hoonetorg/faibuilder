#!/usr/bin/env -S python3 -u
import logging

import os
import sys
import subprocess
import shlex
import shutil
import time

from pathlib import Path

import pwd
import grp

import json

BASEFILESDIRPATH = "/srv/fai/basefiles"
FAIETCDIRPATH = "/srv/fai/etc"
FAICONFIGDIRPATH = "/srv/fai/config"
FAIMIRRORDIRPATH = "/srv/fai/mirror"
FAINFSETCDIRPATH = "/srv/fai/nfsetc"
FAINFSROOTDIRPATH = "/srv/fai/nfsroot"
OUTPUTDIRPATH = "/srv/fai/output"
GLOBALCONF = "/srv/fai/faibuilder.json"
HOSTCONF = "/srv/fai/host.json"


def subprocess_run_wrapper(
    cmd: str, dryrun: bool = False, **kwargs
) -> subprocess.CompletedProcess | None:
    if kwargs.get("shell"):
        wcmd = cmd
    else:
        wcmd = shlex.split(cmd)

    if dryrun:
        logging.info(f"[DRYRUN] {cmd}")
        return None

    logging.info(f"[EXECUTING] {cmd}")
    return subprocess.run(wcmd, **kwargs)


def subprocess_Popen_wrapper(
    cmd: str, dryrun: bool = False, **kwargs
) -> subprocess.Popen | None:
    if kwargs.get("shell"):
        wcmd = cmd
    else:
        wcmd = shlex.split(cmd)

    if dryrun:
        logging.info(f"[DRYRUN] {cmd}")
        return None

    logging.info(f"[EXECUTING] {cmd}")
    return subprocess.Popen(wcmd, **kwargs)


def get_path(path):
    return Path(path).expanduser().absolute()


def split_multi_ext(path: Path):
    suffixes = "".join(path.suffixes)
    if suffixes:
        stem = path.name[: -len(suffixes)]
        ext = suffixes.lstrip(".")
    else:
        stem = path.name
        ext = ""
    return stem, ext


def is_readable_file(file: Path) -> bool:
    return file.exists() and file.is_file() and os.access(file, os.R_OK)


def reset_apt_sources():
    # dirs = [Path("/etc/apt"), Path("/etc/fai/apt")]
    dirs = [Path("/etc/apt")]

    for d in dirs:
        sl = d / "sources.list"
        if sl.exists():
            sl.unlink()
            logging.info(f"Deleted {sl}")

        sldir = d / "sources.list.d"
        if sldir.exists():
            for f in sldir.glob("*.list"):
                f.unlink()
                logging.info(f"Deleted {f}")
            for f in sldir.glob("*.sources"):
                f.unlink()
                logging.info(f"Deleted {f}")

    debcontent = """Types: deb deb-src
URIs: http://127.0.0.1:3142/snapshot.debian.org/archive/debian/20250906T112439Z
Suites: trixie trixie-updates
Components: main non-free-firmware contrib non-free
Enabled: yes
Signed-By: /usr/share/keyrings/debian-archive-keyring.gpg

Types: deb deb-src
URIs: http://127.0.0.1:3142/snapshot.debian.org/archive/debian-security/20250906T161327Z
Suites: trixie-security
Components: main non-free-firmware contrib non-free
Enabled: yes
Signed-By: /usr/share/keyrings/debian-archive-keyring.gpg
"""
    faicontent = """Types: deb
URIs: http://127.0.0.1:3142/fai-project.org/download/
Suites: trixie
Components: koeln
Signed-By: /usr/share/keyrings/fai-project-archive-keyring.gpg
"""

    srccontent = """deb [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] http://127.0.0.1:3142/snapshot.debian.org/archive/debian/20250906T112439Z trixie main non-free-firmware contrib non-free
deb-src [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] http://127.0.0.1:3142/snapshot.debian.org/archive/debian/20250906T112439Z trixie main non-free-firmware contrib non-free

deb [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] http://127.0.0.1:3142/snapshot.debian.org/archive/debian/20250906T112439Z trixie-updates main non-free-firmware contrib non-free
deb-src [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] http://127.0.0.1:3142/snapshot.debian.org/archive/debian/20250906T112439Z trixie-updates main non-free-firmware contrib non-free

deb [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] http://127.0.0.1:3142/snapshot.debian.org/archive/debian-security/20250906T161327Z trixie-security main non-free-firmware contrib non-free
deb-src [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg] http://127.0.0.1:3142/snapshot.debian.org/archive/debian-security/20250906T161327Z trixie-security main non-free-firmware contrib non-free
deb [signed-by=/usr/share/keyrings/fai-project-archive-keyring.gpg] http://127.0.0.1:3142/fai-project.org/download trixie koeln
"""

    for d in dirs:
        sldir = d / "sources.list.d"
        sldir.mkdir(parents=True, exist_ok=True)
        debtarget = sldir / "debian.sources"
        debtarget.write_text(debcontent, encoding="utf-8")
        logging.info(f"Wrote new sources to {debtarget}")

        faitarget = sldir / "fai-project.sources"
        faitarget.write_text(faicontent, encoding="utf-8")
        logging.info(f"Wrote new sources to {faitarget}")

    srctarget = Path("/etc/fai/apt/sources.list")
    srctarget.write_text(srccontent, encoding="utf-8")
    logging.info(f"Wrote new sources.list to {srctarget}")

    nfsroot_conf = Path("/etc/fai/nfsroot.conf")
    if nfsroot_conf.exists():
        text = nfsroot_conf.read_text(encoding="utf-8").splitlines()
        new_lines = []
        for line in text:
            if line.startswith("FAI_DEBOOTSTRAP="):
                new_lines.append(
                    'FAI_DEBOOTSTRAP="trixie http://127.0.0.1:3142/snapshot.debian.org/archive/debian/20250906T112439Z"'
                )
                logging.info(f"Updated FAI_DEBOOTSTRAP in {nfsroot_conf}")
            else:
                new_lines.append(line)
        nfsroot_conf.write_text("\n".join(new_lines) + "\n", encoding="utf-8")


def do_start_acng(fainfsrootdir: Path, basefilesdir: Path, dryrun: bool = False):
    # proxytext = (
    #        'Acquire::http::Proxy "http://127.0.0.1:3142";\n'
    #        'Acquire::https::Proxy "DIRECT";\n'
    #        )

    # aptconfbasedir = "etc/apt/apt.conf.d"

    # globalproxyconf = Path(f"/{aptconfbasedir}/02proxy")
    # nfsrootproxyconf =  fainfsrootdir / Path(f"{aptconfbasedir}/02proxy")

    # for proxyconf in [globalproxyconf, nfsrootproxyconf]:
    #    proxyconf.parent.mkdir(parents=True, exist_ok=True)
    #    proxyconf.write_text(
    #        proxytext,
    #        encoding="utf-8"
    #    )
    #    logging.info(f"Wrote proxy config to {proxyconf}")
    #    logging.info("Content:\n" + proxyconf.read_text(encoding="utf-8"))

    conf_file = Path("/etc/apt-cacher-ng/acng.conf")
    remapsnapdeb = "Remap-snapdeb: snapshot.debian.org/archive ; https://snapshot.debian.org/archive\n"
    remapsnapubu = "Remap-snapubu: snapshot.ubuntu.com ; snapshot.ubuntu.com\n"
    remapfai = (
        "Remap-fai: fai-project.org/download ; https://fai-project.org/download\n"
    )

    # Read current content (create file if missing)
    if conf_file.exists():
        content = conf_file.read_text().splitlines(keepends=True)
    else:
        content = []

    write = False
    if not any(line.startswith("Remap-snapdeb:") for line in content):
        content.append(remapsnapdeb)
        write = True
        logging.info("Added Remap-snapdeb entry to content")
    else:
        logging.info(" Remap-snapdeb entry already exists")

    if not any(line.startswith("Remap-snapubu:") for line in content):
        content.append(remapsnapubu)
        write = True
        logging.info("Added Remap-snapubu entry to content")
    else:
        logging.info(" Remap-snapubu entry already exists")

    if not any(line.startswith("Remap-fai:") for line in content):
        content.append(remapfai)
        write = True
        logging.info("Added Remap-fai entry to content")
    else:
        logging.info(" Remap-fai entry already exists")

    if write:
        conf_file.write_text("".join(content))
        logging.info("Rewrote acng.conf")

    acng = subprocess_Popen_wrapper(
        "/usr/sbin/apt-cacher-ng -c /etc/apt-cacher-ng ForeGround=1", dryrun=dryrun
    )

    if acng is not None:
        logging.info(f"apt-cacher-ng started with PID {acng.pid}")
        time.sleep(2)

    return acng


def do_faimirror(
    faiclasses: list, faietcdir: Path, faimirrordir: Path, dryrun: bool = False
):
    faimirrormarker = faimirrordir / "mirror-is-up-to-date"

    logging.info("Checking mirror freshness")

    if faimirrormarker.is_file():
        logging.info(
            f"Mirror is up to date, faimirror marker file is existing {shlex.quote(str(faimirrormarker))}"
        )
        return

    logging.info(
        f"Mirror is outdated or missing, faimirror marker file {shlex.quote(str(faimirrormarker))} is not a file - running fai-mirror"
    )

    cleanupfiles = []
    aptkeysdirsrc = faietcdir / "apt" / "trusted.gpg.d"
    aptkeysdirdest = Path("/etc/apt/trusted.gpg.d")

    if aptkeysdirsrc.exists():
        aptkeysdirdest.mkdir(parents=True, exist_ok=True)
        aptkeyfilessrc = aptkeysdirsrc.glob("*.gpg")
        for k in aptkeyfilessrc:
            d = aptkeysdirdest / k.name
            cleanupfiles.append(d)
            logging.info(f"Copying {shlex.quote(str(k))} to {shlex.quote(str(d))}")
            shutil.copy2(k, d)

    aptconfdirsrc = faietcdir / "apt" / "apt.conf.d"
    aptconfdirdest = Path("/etc/apt/apt.conf.d")

    if aptconfdirsrc.exists():
        aptconfdirdest.mkdir(parents=True, exist_ok=True)
        aptconffilessrc = aptconfdirsrc.glob("*.conf")
        for c in aptconffilessrc:
            d = aptconfdirdest / c.name
            cleanupfiles.append(d)
            logging.info(f"Copying {shlex.quote(str(c))} to {shlex.quote(str(d))}")
            shutil.copy2(c, d)

    subprocess_run_wrapper(
        cmd=(
            "fai-mirror -b -m1 "
            f"-C {shlex.quote(str(faietcdir))} "
            f"-c '{','.join(faiclasses)},GRUB_PC,GRUB_EFI,AMD64,FB' "
            f"{shlex.quote(str(faimirrordir))}"
        ),
        dryrun=dryrun,
    )

    if not dryrun:
        logging.info(
            f"Mirror finished, touching faimirror marker file: {shlex.quote(str(faimirrormarker))}"
        )
        faimirrormarker.touch()

    for f in cleanupfiles:
        logging.info(f"Deleting {shlex.quote(str(f))} after mirroring")
        f.unlink()


def do_make_basefile(
    basefilesdir: Path, basefile: Path, faiconfigdir: Path, dryrun: bool = False
):
    basefilefull = basefilesdir / basefile

    logging.info(f"Checking if basefile {shlex.quote(str(basefilefull))} exists")

    if basefilefull.is_file():
        logging.info(f"Basefile {shlex.quote(str(basefilefull))} already exists")
        return

    logging.info(
        f"Basefile {shlex.quote(str(basefilefull))} is outdated or missing - running mk-basefile"
    )

    basefilebase, basefileext = split_multi_ext(basefile)

    subprocess_run_wrapper(
        cmd=(
            f"{shlex.quote(str(faiconfigdir / 'basefiles' / 'mk-basefile'))} -J {shlex.quote(str(basefilebase))}"
        ),
        dryrun=dryrun,
        cwd=basefilesdir,
    )


def do_make_fainfsroot(
    faietcdir: Path,
    fainfsrootdir: Path,
    basefilesdir: Path,
    basefile: Path,
    dryrun: bool = False,
):
    fainfsrootmarker = fainfsrootdir / ".THIS_IS_THE_FAI_NFSROOT"

    basefilefull = basefilesdir / basefile

    logging.info("Checking NFSROOT freshness")

    if fainfsrootmarker.is_file():
        logging.info(
            f"NFSROOT seems to be ready - fainfsroot marker file {shlex.quote(str(fainfsrootmarker))} already exists"
        )
        return

    logging.info(
        f"NFSROOT is outdated or missing fainfsroot marker file {shlex.quote(str(fainfsrootmarker))} is not a file - running fai-make-nfsroot"
    )

    hooksdir = Path("/etc/fai/nfsroot-hooks")

    logging.info(f"Creating {shlex.quote(str(hooksdir))}")
    hooksdir.mkdir(parents=True, exist_ok=True)

    src = Path("/usr/local/etc/50-add-btrfs")
    dest = hooksdir / src.name

    logging.info(
        f"Copying {shlex.quote(str(src))} to {shlex.quote(str(dest))} and make it executable"
    )
    shutil.copy2(src, dest)

    # chmod +x
    mode = dest.stat().st_mode
    dest.chmod(mode | 0o111)

    logging.info(
        f"Content of {shlex.quote(str(dest))}:\n{str(dest.read_text(encoding='utf-8'))}"
    )

    subprocess_run_wrapper(
        cmd=(
            f"fai-make-nfsroot -C {shlex.quote(str(faietcdir))} -B {shlex.quote(str(basefilefull))} -N -f -v"
        ),
        dryrun=dryrun,
    )


def do_build_iso(
    faiclasses: list,
    hostconf: dict,
    faietcdir: Path,
    faiconfigdir: Path,
    faimirrordir: Path,
    outputdir: Path,
    dryrun: bool = False,
):

    classesfile = faiconfigdir / "class" / "50-host-classes"

    keymap = str(hostconf["keymap"])
    timezone = str(hostconf["timezone"])
    rootpw = str(hostconf["rootpw"])
    username = str(hostconf["username"])
    userpw = str(hostconf["userpw"])
    diskpath = Path(hostconf["diskpath"])
    rootsizemib = int(hostconf["rootsizemib"])
    cryptpw = str(hostconf["cryptpw"])
    outfile = Path(hostconf["outfile"])

    outfilefull = outputdir / outfile

    if outfilefull.is_file():
        logging.info(
            f"ISO already exists: {shlex.quote(str(outfilefull))} - refusing to overwrite."
        )
        return

    logging.info(f"Building FAI ISO {shlex.quote(str(outfilefull))} with faicd")

    logging.info("hostconf:")
    logging.info(f"keymap: {str(keymap)}")
    logging.info(f"timezone: {str(timezone)}")
    logging.info("rootpw: hidden")
    logging.info(f"username: {str(username)}")
    logging.info("userpw: hidden")
    logging.info(f"diskpath: {shlex.quote(str(diskpath))}")
    logging.info(f"rootsizemib: {int(rootsizemib)}")
    logging.info("cryptpw: hidden")
    logging.info(f"outfile: {shlex.quote(str(outfile))}")

    content = (
        "#!/bin/bash\n"
        "# generated by faibuilder\n"
        f"echo '{' '.join(faiclasses)} FB'\n"
    )
    if dryrun:
        logging.info(
            f"[DRYRUN] Would write to {shlex.quote(str(classesfile))}:\n{content.strip()}"
        )
    else:
        logging.info(f"Writing to {shlex.quote(str(classesfile))}:\n{content.strip()}")
        classesfile.write_text(content)

    logging.info(f"Making {shlex.quote(str(classesfile))} executable")
    classesfilemode = classesfile.stat().st_mode
    classesfile.chmod(classesfilemode | 0o111)

    variablesfile = faiconfigdir / "class" / "FB.var"
    content = (
        "# generated by faibuilder\n"
        f"KEYMAP='{str(keymap)}'\n"
        f"TIMEZONE='{str(timezone)}'\n"
        f"ROOTPW={shlex.quote(str(rootpw))}\n"
        f"username='{str(username)}'\n"
        f"USERPW={shlex.quote(str(userpw))}\n"
        f"DISKPATH={shlex.quote(str(diskpath))}\n"
        f"CRYPTPW={shlex.quote(str(cryptpw))}\n"
        f"ROOTSIZEMIB='{int(rootsizemib)}'\n"
    )

    if dryrun:
        logging.info(
            f"[DRYRUN] Would write to {shlex.quote(str(variablesfile))}\n{content.strip()}"
        )
    else:
        logging.info(f"Writing to {shlex.quote(str(variablesfile))}\n{content.strip()}")
        variablesfile.write_text(content)

    subprocess_run_wrapper(
        cmd=(
            "fai-cd "
            f"-C {shlex.quote(str(faietcdir))} "
            f"-g {shlex.quote(str(faiconfigdir / 'grub.cfg'))} "
            f"-m {shlex.quote(str(faimirrordir))} "
            f"{shlex.quote(str(outfilefull))}"
        ),
        dryrun=dryrun,
    )

    imgfilefull = outfilefull.with_suffix(".img")

    logging.info(
        f"Now that we created an ISO {shlex.quote(str(outfilefull))}, delete {shlex.quote(str(imgfilefull))} if exists, because it is outdated"
    )
    if imgfilefull.is_file():
        imgfilefull.unlink()

    logging.info(
        f"Cleanup {shlex.quote(str(classesfile))} and  {shlex.quote(str(variablesfile))} if exists"
    )
    for f in [classesfile, variablesfile]:
        if f.is_file():
            f.unlink()


def do_build_img_from_iso(
    isofilefull: Path,
    dryrun: bool = False,
):

    imgfilefull = isofilefull.with_suffix(".img")

    if imgfilefull.is_file():
        logging.info(
            f"IMG already exists: {shlex.quote(str(imgfilefull))} - refusing to overwrite."
        )
        return

    logging.info(
        f"Creating IMG file {shlex.quote(str(imgfilefull))} from ISO file {shlex.quote(str(isofilefull))}"
    )

    if not is_readable_file(file=isofilefull):
        logging.error(
            f"\nISO file {shlex.quote(str(isofilefull))} does not exist - Exiting"
        )
        sys.exit(1)

    logging.info(f"Processing file: {shlex.quote(str(isofilefull))}")

    isopath = Path("/iso")
    efipath = Path("/efi")
    cdpath = Path("/cd")

    for p in {isopath, efipath, cdpath}:
        p.mkdir(parents=True, exist_ok=True)

    imagesizegb = 3
    efilabel = "EFI"
    cdlabel = "FAI_CD"

    logging.info("Mounting ISO contents")
    subprocess_run_wrapper(
        cmd=(
            f"mount -o loop,ro {shlex.quote(str(isofilefull))} {shlex.quote(str(isopath))}"
        ),
        dryrun=dryrun,
    )

    logging.info("Creating disk image")
    subprocess_run_wrapper(
        cmd=(
            f"qemu-img create -f raw -o preallocation=off {shlex.quote(str(imgfilefull))} {int(imagesizegb)}G"
        ),
        dryrun=dryrun,
    )

    logging.info("Partitioning the disk")
    subprocess_run_wrapper(
        cmd=(
            "parted --script "
            f"{shlex.quote(str(imgfilefull))} "
            "mklabel gpt "
            "mkpart primary fat32 1MiB 125MiB "
            "mkpart primary ext4 125MiB 100%"
        ),
        dryrun=dryrun,
    )

    logging.info("Mapping partitions")
    try:
        result = subprocess_run_wrapper(
            cmd=(f"losetup --show -fP {shlex.quote(str(imgfilefull))}"),
            dryrun=dryrun,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True,
        )

        loopdevice = Path(result.stdout.strip())
        logging.info(f"loopdevice:\n{shlex.quote(str(loopdevice))}")
    except subprocess.CalledProcessError as err:
        logging.error(f"losetup failed: {err.stderr}")
        sys.exit(1)

    subprocess_run_wrapper(
        cmd=(f"kpartx -av {shlex.quote(str(loopdevice))}"),
        dryrun=dryrun,
    )

    part1 = Path("/dev/mapper") / (loopdevice.name + "p1")
    part2 = Path("/dev/mapper") / (loopdevice.name + "p2")

    logging.info("Formatting and mounting partitions")

    subprocess_run_wrapper(
        cmd=(f"mkfs.vfat -F 32 -n {efilabel} {shlex.quote(str(part1))}"),
        dryrun=dryrun,
    )
    subprocess_run_wrapper(
        cmd=(f"mount {shlex.quote(str(part1))} {shlex.quote(str(efipath))}"),
        dryrun=dryrun,
    )
    # subprocess_run_wrapper(
    #     cmd=(f"mkfs.ext4 -L {cdlabel} {shlex.quote(str(part2))}"),
    #     dryrun=dryrun,
    # )
    subprocess_run_wrapper(
        cmd=(
            f"mkfs.btrfs --data single --metadata dup -L {cdlabel} {shlex.quote(str(part2))}"
        ),
        dryrun=dryrun,
    )
    subprocess_run_wrapper(
        cmd=(f"mount {shlex.quote(str(part2))} {shlex.quote(str(cdpath))}"),
        dryrun=dryrun,
    )

    subprocess_run_wrapper(
        cmd=(
            "grub-install "
            f"--efi-directory={shlex.quote(str(efipath))} "
            f"--boot-directory={shlex.quote(str(efipath))} "
            "--target=x86_64-efi "
            "--no-nvram "
            "--removable "
            "--uefi-secure-boot "
        ),
        dryrun=dryrun,
    )

    subprocess_run_wrapper(
        cmd=(
            "rsync "
            "-av "
            "--exclude=EFI/ "
            f"{shlex.quote(str(isopath) + '/')} "
            f"{shlex.quote(str(cdpath) + '/')}"
        ),
        dryrun=dryrun,
    )

    (efipath / "EFI" / "BOOT").mkdir(parents=True, exist_ok=True)

    subprocess_run_wrapper(
        cmd=(
            "rsync "
            "-av "
            "/usr/local/etc/grub.cfg "
            f"{shlex.quote(str(efipath / 'EFI' / 'BOOT'))} "
        ),
        dryrun=dryrun,
    )

    subprocess_run_wrapper(
        cmd=(f"umount {shlex.quote(str(efipath))}"),
        dryrun=dryrun,
    )

    subprocess_run_wrapper(
        cmd=(f"umount {shlex.quote(str(cdpath))}"),
        dryrun=dryrun,
    )

    logging.info("Cleaning up")
    subprocess_run_wrapper(
        cmd=(f"kpartx -d {shlex.quote(str(loopdevice))}"),
        dryrun=dryrun,
    )

    subprocess_run_wrapper(
        cmd=(f"losetup -d {shlex.quote(str(loopdevice))}"),
        dryrun=dryrun,
    )

    subprocess_run_wrapper(
        cmd=(f"umount {shlex.quote(str(isopath))}"),
        dryrun=dryrun,
    )

    logging.info(f"Disk image {imgfilefull} created successfully")


def main():
    dryrun = False
    logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")

    basefilesdir = get_path(BASEFILESDIRPATH)
    faietcdir = get_path(FAIETCDIRPATH)
    faiconfigdir = get_path(FAICONFIGDIRPATH)
    faimirrordir = get_path(FAIMIRRORDIRPATH)
    fainfsetcdir = get_path(FAINFSETCDIRPATH)
    fainfsrootdir = get_path(FAINFSROOTDIRPATH)
    outputdir = get_path(OUTPUTDIRPATH)

    logging.info(f"basefilesdir: {shlex.quote(str(basefilesdir))}")
    logging.info(f"faietcdir: {shlex.quote(str(faietcdir))}")
    logging.info(f"faiconfigdir: {shlex.quote(str(faiconfigdir))}")
    logging.info(f"faimirrordir: {shlex.quote(str(faimirrordir))}")
    logging.info(f"fainfsetcdir: {shlex.quote(str(fainfsetcdir))}")
    logging.info(f"fainfsrootdir: {shlex.quote(str(fainfsrootdir))}")
    logging.info(f"outputdir: {shlex.quote(str(outputdir))}")

    # 0
    root_uid = pwd.getpwnam("root").pw_uid
    root_gid = grp.getgrnam("root").gr_gid

    for d in [basefilesdir, faimirrordir, fainfsrootdir, outputdir]:
        if d.exists():
            os.chown(d, root_uid, root_gid)
            d.chmod(0o755)
        else:
            logging.info(f"[WARN] Directory does not exist: {shlex.quote(str(d))}")

    globalconffile = get_path(GLOBALCONF)
    if not is_readable_file(file=globalconffile):
        logging.error(
            f"Config file not found or not readable: {shlex.quote(str(globalconffile))}"
        )
        sys.exit(1)
    logging.info(f"globalconffile: {shlex.quote(str(globalconffile))}")
    globalconf = json.loads(globalconffile.read_text(encoding="utf-8"))
    logging.info(f"globalconf:\n{json.dumps(globalconf, indent=2)}")

    basefilenfs = Path(globalconf["basefilenfs"])
    logging.info(f"basefilenfs: {basefilenfs}")

    hostconffile = get_path(HOSTCONF)
    if not is_readable_file(file=hostconffile):
        logging.error(
            f"Config file not found or not readable: {shlex.quote(str(hostconffile))}"
        )
        sys.exit(1)
    logging.info(f"hostconffile: {shlex.quote(str(hostconffile))}")
    hostconf = json.loads(hostconffile.read_text(encoding="utf-8"))
    logging.info(f"hostconf:\n{json.dumps(hostconf, indent=2)}")

    faiclasses = hostconf["faiclasses"]
    basefile = Path(hostconf["basefile"])
    basefileclass = hostconf["basefileclass"]
    outfile = Path(hostconf["outfile"])

    logging.info(f"faiclasses: {faiclasses}")
    logging.info(f"basefile: {shlex.quote(str(basefile))}")
    logging.info(f"outfile: {shlex.quote(str(outfile))}")

    reset_apt_sources()

    acng = do_start_acng(
        fainfsrootdir=fainfsrootdir, basefilesdir=basefilesdir, dryrun=dryrun
    )

    do_faimirror(
        faiclasses=faiclasses,
        faietcdir=faietcdir,
        faimirrordir=faimirrordir,
        dryrun=dryrun,
    )

    for b in [basefile, basefilenfs]:
        do_make_basefile(
            basefilesdir=basefilesdir,
            basefile=b,
            faiconfigdir=faiconfigdir,
            dryrun=dryrun,
        )

    basefilefull = basefilesdir / basefile
    basefiledest = faiconfigdir / "basefiles" / f"{basefileclass}.tar.xz"
    logging.info(
        f"Copying {shlex.quote(str(basefilefull))} to {shlex.quote(str(basefiledest))}"
    )
    shutil.copy2(basefilefull, basefiledest)

    do_make_fainfsroot(
        faietcdir=fainfsetcdir,
        fainfsrootdir=fainfsrootdir,
        basefilesdir=basefilesdir,
        basefile=basefilenfs,
        dryrun=dryrun,
    )

    acng.terminate()
    acng.wait()

    do_build_iso(
        faiclasses=faiclasses,
        hostconf=hostconf,
        faietcdir=faietcdir,
        faiconfigdir=faiconfigdir,
        faimirrordir=faimirrordir,
        outputdir=outputdir,
        dryrun=dryrun,
    )

    do_build_img_from_iso(
        isofilefull=outputdir / outfile,
        dryrun=dryrun,
    )

    logging.info(f"Deleting {shlex.quote(str(basefiledest))}")
    basefiledest.unlink()


if __name__ == "__main__":
    main()
